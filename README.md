# SBP Analyzer (Ad-hoc Analysis Focus)

SBP Analyzer æ˜¯ä¸€å€‹ç”¨æ–¼ **Ad-hoc (é›¢ç·š) åˆ†æ** å·²å®Œæˆçš„æ·±åº¦å­¸ç¿’æ¨¡å‹è¨“ç·´éç¨‹çš„ Python å¥—ä»¶ã€‚
å®ƒå°ˆç‚ºåˆ†æ MicDysphagiaFramework ç”¢ç”Ÿçš„å¯¦é©—çµæœè€Œè¨­è¨ˆï¼Œæ—¨åœ¨å¹«åŠ©é–‹ç™¼è€…æ·±å…¥ç†è§£æ¨¡å‹è¡Œç‚ºã€è¨“ç·´å‹•æ…‹å’Œæ½›åœ¨å•é¡Œã€‚

## å°ˆæ¡ˆçµæ§‹

```
SBP_analyzer/
â”œâ”€â”€ analyzer/                    # æ ¸å¿ƒåˆ†æé‚è¼¯
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_analyzer.py
â”‚   â”œâ”€â”€ model_structure_analyzer.py    # å¢å¼·ï¼šç¾æ”¯æŒè¤‡é›œåº¦å’Œæ•ˆç‡åˆ†æ
â”‚   â”œâ”€â”€ training_dynamics_analyzer.py
â”‚   â””â”€â”€ intermediate_data_analyzer.py
â”œâ”€â”€ data_loader/                 # æ•¸æ“šè¼‰å…¥èˆ‡è§£æ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_loader.py
â”‚   â”œâ”€â”€ experiment_loader.py
â”‚   â””â”€â”€ hook_data_loader.py
â”œâ”€â”€ metrics/                     # åˆ†ææŒ‡æ¨™è¨ˆç®—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ distribution_metrics.py
â”‚   â”œâ”€â”€ performance_metrics.py
â”‚   â””â”€â”€ layer_activity_metrics.py  # æ–°å¢ï¼šå±¤ç´šæ´»å‹•æŒ‡æ¨™è¨ˆç®—
â”œâ”€â”€ visualization/               # è¦–è¦ºåŒ–åŠŸèƒ½ (æ‰€æœ‰æ¨¡çµ„å·²å®Œæˆå¯¦ç¾)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ plotter.py               # æ‰€æœ‰ç¹ªåœ–åŠŸèƒ½çš„åŸºé¡
â”‚   â”œâ”€â”€ distribution_plots.py    # åˆ†å¸ƒè¦–è¦ºåŒ–
â”‚   â”œâ”€â”€ performance_plots.py     # æ€§èƒ½æŒ‡æ¨™è¦–è¦ºåŒ–
â”‚   â””â”€â”€ model_structure_plots.py # æ¨¡å‹çµæ§‹è¦–è¦ºåŒ–
â”œâ”€â”€ reporter/                    # å ±å‘Šç”Ÿæˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ report_generator.py
â”œâ”€â”€ utils/                       # é€šç”¨å·¥å…·
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ file_utils.py
â”‚   â”œâ”€â”€ tensor_utils.py
â”‚   â””â”€â”€ stat_utils.py
â”œâ”€â”€ interfaces/                  # ç”¨æˆ¶æ¥å£
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ analyzer_interface.py
â”œâ”€â”€ examples/                    # ä½¿ç”¨ç¯„ä¾‹
â”‚   â””â”€â”€ model_analysis_example.py
â””â”€â”€ tests/                       # æ¸¬è©¦æ¨¡çµ„
    â”œâ”€â”€ test_data/
    â”œâ”€â”€ test_layer_activity_metrics.py  # æ–°å¢ï¼šå±¤ç´šæ´»å‹•æŒ‡æ¨™æ¸¬è©¦
    â”œâ”€â”€ test_distribution_plots.py
    â”œâ”€â”€ test_performance_plots.py
    â”œâ”€â”€ test_model_structure_analyzer.py
    â””â”€â”€ ...
```

## ä¸»è¦åŠŸèƒ½

* **æ•¸æ“šè¼‰å…¥**: å¾ MicDysphagiaFramework å¯¦é©—çµæœç›®éŒ„è¼‰å…¥é…ç½®ã€æ¨¡å‹çµæ§‹ã€è¨“ç·´æ­·å²å’Œ hook æ•¸æ“šã€‚
* **æ¨¡å‹çµæ§‹åˆ†æ**: è§£æä¸¦è¦–è¦ºåŒ–æ¨¡å‹æ¶æ§‹å’Œåƒæ•¸åˆ†å¸ƒã€‚
  * å±¤ç´šè¤‡é›œåº¦è¨ˆç®—ã€åƒæ•¸æ•ˆç‡åˆ†æã€FLOPsä¼°ç®—ã€é€£æ¥æ€§åˆ†æ
  * æ”¯æŒå¤šç¨®æ¨¡å‹æ¶æ§‹é¡å‹ (Transformer, Swin, ViT, GNNç­‰)
* **è¨“ç·´å‹•æ…‹åˆ†æ**: åˆ†ææå¤±å‡½æ•¸å’Œè©•ä¼°æŒ‡æ¨™çš„è¶¨å‹¢å’Œç©©å®šæ€§ã€‚
* **ä¸­é–“å±¤æ•¸æ“šåˆ†æ**: åˆ†ææ¨¡å‹å…§éƒ¨æ¿€æ´»å€¼çš„åˆ†ä½ˆå’Œçµ±è¨ˆç‰¹æ€§ã€‚
  * **æ–°å¢**: å±¤ç´šæ´»å‹•æŒ‡æ¨™è¨ˆç®—ï¼ŒåŒ…æ‹¬æ¿€æ´»å€¼çµ±è¨ˆã€ç¨€ç–åº¦ã€é£½å’Œåº¦ã€æœ‰æ•ˆç§©å’Œç‰¹å¾µä¸€è‡´æ€§åˆ†æ
  * **æ–°å¢**: æ­»äº¡ç¥ç¶“å…ƒæª¢æ¸¬ã€å±¤é–“ç›¸ä¼¼åº¦å’Œæ¿€æ´»å€¼å‹•æ…‹è®ŠåŒ–åˆ†æ
* **è¦–è¦ºåŒ–**: æä¾›å¤šç¨®åœ–è¡¨ä¾†å±•ç¤ºåˆ†æçµæœã€‚
  * åˆ†å¸ƒè¦–è¦ºåŒ– (ç›´æ–¹åœ–ã€ç®±å½¢åœ–ã€Q-Qåœ–ç­‰)
  * æ€§èƒ½æŒ‡æ¨™è¦–è¦ºåŒ– (æå¤±æ›²ç·šã€æ”¶æ–‚åˆ†æã€è¨“ç·´ç©©å®šæ€§ç­‰)
  * æ¨¡å‹çµæ§‹è¦–è¦ºåŒ–ï¼Œæ”¯æŒå„ç¨®è¤‡é›œç¶²çµ¡
* **å ±å‘Šç”Ÿæˆ**: è‡ªå‹•ç”Ÿæˆçµæ§‹åŒ–çš„åˆ†æå ±å‘Š (HTML/Markdown)ã€‚

## æ”¯æŒçš„æ•¸æ“šçµæ§‹

SBP Analyzer å°ˆç‚ºåˆ†æä»¥ä¸‹ MicDysphagiaFramework ç”¢ç”Ÿçš„å¯¦é©—çµæœç›®éŒ„çµæ§‹è¨­è¨ˆï¼š

```
results/
â””â”€â”€ {å¯¦é©—åç¨±}_{æ™‚é–“æˆ³}/               # ä¾‹ï¼šaudio_swin_regression_20250417_142912/
    â”œâ”€â”€ config.json                 # å¯¦é©—é…ç½®æ–‡ä»¶
    â”œâ”€â”€ model_structure.json        # æ¨¡å‹çµæ§‹ä¿¡æ¯
    â”œâ”€â”€ training_history.json       # è¨“ç·´æ­·å²è¨˜éŒ„
    â”œâ”€â”€ models/                     # æ¨¡å‹æ¬Šé‡ä¿å­˜ç›®éŒ„
    â”œâ”€â”€ hooks/                      # æ¨¡å‹é‰¤å­æ•¸æ“š
    â”‚   â”œâ”€â”€ training_summary.pt     # æ•´é«”è¨“ç·´æ‘˜è¦
    â”‚   â”œâ”€â”€ evaluation_results_test.pt  # æ¸¬è©¦é›†è©•ä¼°çµæœ
    â”‚   â””â”€â”€ epoch_N/                # å„è¼ªæ¬¡æ•¸æ“š
    â””â”€â”€ results/                    # å¯¦é©—çµæœ
        â””â”€â”€ results.json            # æœ€çµ‚çµæœæ‘˜è¦
```

## å®‰è£

```bash
pip install -e .
```

## ä½¿ç”¨ç¯„ä¾‹

### åŸºæœ¬ä½¿ç”¨æ–¹å¼

```python
from sbp_analyzer.interfaces.analyzer_interface import SBPAnalyzer

# æŒ‡å‘ MicDysphagiaFramework ç”¢ç”Ÿçš„å¯¦é©—çµæœç›®éŒ„
analyzer = SBPAnalyzer(experiment_dir='results/audio_swin_regression_20250417_142912')

# é‹è¡Œåˆ†æ
analysis_results = analyzer.analyze(
    analyze_model_structure=True,
    analyze_training_history=True,
    analyze_hooks=True,
    epochs=[0, 5, 10],  # å¯é¸æ“‡æŒ‡å®šè¦åˆ†æçš„ç‰¹å®šè¼ªæ¬¡
    layers=['patch_embed', 'layers.0']  # å¯é¸æ“‡æŒ‡å®šè¦åˆ†æçš„ç‰¹å®šå±¤
)

# ç”Ÿæˆå ±å‘Š
analyzer.generate_report(output_dir='./analysis_report', report_format='html')

# æˆ–è€…ï¼Œç›´æ¥è¨ªå•ç‰¹å®šåˆ†æçµæœ
model_summary = analysis_results.get_model_summary()
loss_curve_plot = analysis_results.get_plot('loss_curve')
layer_activation_dist = analysis_results.get_activation_distribution('patch_embed', epoch=0)

print("åˆ†æå®Œæˆï¼Œå ±å‘Šå·²ç”Ÿæˆæ–¼ ./analysis_report")
```

### ä½¿ç”¨å±¤ç´šæ´»å‹•åˆ†æåŠŸèƒ½

```python
import torch
from metrics.layer_activity_metrics import (
    calculate_activation_statistics,
    calculate_activation_sparsity,
    detect_dead_neurons,
    calculate_layer_similarity
)

# å‡è¨­é€™æ˜¯æŸå±¤çš„æ¿€æ´»å€¼
activations = torch.randn(32, 64, 16, 16)  # [batch, channels, height, width]

# è¨ˆç®—æ¿€æ´»å€¼çš„çµ±è¨ˆæŒ‡æ¨™
stats = calculate_activation_statistics(activations)
print(f"å±¤æ¿€æ´»å€¼å‡å€¼: {stats['mean']:.4f}, æ¨™æº–å·®: {stats['std']:.4f}")
print(f"ç¨€ç–åº¦: {stats['sparsity']:.2f}, ç†µ: {stats['entropy']:.2f}")

# æª¢æ¸¬æ­»äº¡ç¥ç¶“å…ƒ
dead_info = detect_dead_neurons(activations)
print(f"æ­»äº¡ç¥ç¶“å…ƒæ•¸é‡: {dead_info['dead_count']}, æ¯”ä¾‹: {dead_info['dead_ratio']:.2%}")

# æ¯”è¼ƒå…©å±¤çš„ç›¸ä¼¼åº¦
layer1 = torch.randn(32, 100)
layer2 = torch.randn(32, 100)
similarity = calculate_layer_similarity(layer1, layer2)
print(f"å±¤é–“ç›¸ä¼¼åº¦: {similarity['cosine_similarity']:.4f}")
```

### ä½¿ç”¨è¦–è¦ºåŒ–æ¨¡çµ„

```python
import numpy as np
from visualization.distribution_plots import DistributionPlotter
from visualization.performance_plots import PerformancePlotter

# å‰µå»ºåˆ†å¸ƒè¦–è¦ºåŒ–å™¨
dist_plotter = DistributionPlotter(output_dir='./plots')

# ç¹ªè£½æ¬Šé‡åˆ†å¸ƒç›´æ–¹åœ–
weights = np.random.normal(0, 0.1, 1000)
dist_plotter.plot_histogram(weights, title='Weight Distribution', filename='weights.png')

# æ¯”è¼ƒå¤šå€‹åˆ†å¸ƒ
distributions = {
    'Conv1': np.random.normal(0, 0.1, 1000),
    'Conv2': np.random.normal(0, 0.05, 1000),
    'FC': np.random.normal(0, 0.2, 1000)
}
dist_plotter.plot_distribution_comparison(distributions, title='Layer Comparisons')

# å‰µå»ºæ€§èƒ½è¦–è¦ºåŒ–å™¨
perf_plotter = PerformancePlotter(output_dir='./plots')

# ç¹ªè£½æå¤±æ›²ç·š
loss_history = {
    'train': [2.0, 1.8, 1.5, 1.3, 1.1, 0.9, 0.8, 0.7, 0.6, 0.5],
    'val': [2.1, 1.9, 1.6, 1.4, 1.2, 1.0, 0.9, 0.85, 0.8, 0.75]
}
perf_plotter.plot_loss_curve(loss_history, title='Training Loss')
```

### å®Œæ•´ç¤ºä¾‹

æŸ¥çœ‹ `examples/model_analysis_example.py` äº†è§£å¦‚ä½•é€²è¡Œå®Œæ•´çš„æ¨¡å‹åˆ†æå’Œè¦–è¦ºåŒ–æµç¨‹ã€‚

## é–‹ç™¼é€²åº¦

ç›®å‰å·²å®Œæˆ:
- âœ… æ¨¡å‹çµæ§‹åˆ†æåŠŸèƒ½
- âœ… è¨“ç·´å‹•æ…‹åˆ†æåŠŸèƒ½
- âœ… è¦–è¦ºåŒ–æ¨¡çµ„ (åˆ†å¸ƒã€æ€§èƒ½å’Œæ¨¡å‹çµæ§‹è¦–è¦ºåŒ–)
- âœ… å±¤ç´šæ´»å‹•æŒ‡æ¨™è¨ˆç®—åŠŸèƒ½

æ­£åœ¨é€²è¡Œä¸­:
- ğŸ”„ ä¸­é–“å±¤æ•¸æ“šåŠ è¼‰èˆ‡è™•ç†
- ğŸ”„ å±¤ç´šè¡Œç‚ºåˆ†æç®—æ³•
- ğŸ”„ å ±å‘Šç”Ÿæˆå™¨å¯¦ç¾

## è²¢ç»

æ­¡è¿æäº¤Pull Requestæˆ–å»ºç«‹Issuesä¾†æ”¹é€²æœ¬é …ç›®ã€‚è«‹ç¢ºä¿æ–°ä»£ç¢¼åŒ…å«é©ç•¶çš„æ¸¬è©¦å’Œæ–‡æª”ã€‚

## æ›´å¤šè³‡è¨Š

è©³ç´°çš„é–‹ç™¼è·¯ç·šåœ–å’Œè¨­è¨ˆè«‹åƒè¦‹ `Instructor.md`ã€‚
